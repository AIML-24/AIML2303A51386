{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIML-24/AIML2303A51386/blob/main/AIML_A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with Titanic data set\n",
        "## 2303A51372\n",
        "## Haripriya"
      ],
      "metadata": {
        "id": "IOn8bFerJxRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages and dataset"
      ],
      "metadata": {
        "id": "-qjzx3geJ4w8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import nbconvert #recode the dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "train = pd.read_csv('/content/titanic_train.csv') # Training set is already available\n",
        "train.head()"
      ],
      "metadata": {
        "id": "k2e_bQGfJ-rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check basic info about the data set\n",
        "including missing value"
      ],
      "metadata": {
        "id": "ITKZTNkyKF-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 891 entries, 0 to 890\n",
        "Data columns (total 12 columns):\n",
        " #   Column       Non-Null Count  Dtype\n",
        "---  ------       --------------  -----\n",
        " 0   PassengerId  891 non-null    int64\n",
        " 1   Survived     891 non-null    int64\n",
        " 2   Pclass       891 non-null    int64\n",
        " 3   Name         891 non-null    object\n",
        " 4   Sex          891 non-null    object\n",
        " 5   Age          714 non-null    float64\n",
        " 6   SibSp        891 non-null    int64\n",
        " 7   Parch        891 non-null    int64\n",
        " 8   Ticket       891 non-null    object\n",
        " 9   Fare         891 non-null    float64\n",
        " 10  Cabin        204 non-null    object\n",
        " 11  Embarked     889 non-null    object\n",
        "dtypes: float64(2), int64(5), object(5)\n",
        "memory usage: 83.7+ KB"
      ],
      "metadata": {
        "id": "kR3wmwc2KIJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d=train.describe(percentiles=[.25,.5])\n",
        "d"
      ],
      "metadata": {
        "id": "I4BItDSlKPNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory analysis and plots"
      ],
      "metadata": {
        "id": "O2ETFh8DKT0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot a bar diagram to check the number of numeric entries\n",
        "\n",
        "From the bar diagram, it shows that there are some age entries missing as the number of count for 'Age' is less than the other counts.\n",
        "We can do some impute/transformation of the data to fill-up the missing entries."
      ],
      "metadata": {
        "id": "MAhvwn1tKXlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dT=d.T\n",
        "dT.plot.bar(y='count')\n",
        "plt.title(\"Bar plot of the count of numeric features\",\n",
        "          fontsize=17)\n",
        "plt.xlabel(\"Numeric features\",fontsize=17)\n",
        "plt.ylabel(\"Count\",fontsize=17)"
      ],
      "metadata": {
        "id": "wpMBK8REKiZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Check the relative size of survived and not-survived"
      ],
      "metadata": {
        "id": "HcWdXkftKqhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.countplot(x='Survived',hue='Fare',data=train,\n",
        "              palette='rainbow')\n",
        "#sns.pairplot(train)"
      ],
      "metadata": {
        "id": "k9Xrk8YTKrw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Is there a pattern for the survivability based on sex?\n",
        "\n",
        "It looks like more female survived than males!"
      ],
      "metadata": {
        "id": "C22wePMvK7kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.countplot(x='Survived',hue='Sex',data=train,\n",
        "              palette='rainbow')"
      ],
      "metadata": {
        "id": "daU_IsNtK-hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What about any pattern related to passenger class?\n",
        "\n",
        "It looks like disproportionately large number of 3rd class passengers died!"
      ],
      "metadata": {
        "id": "zqKhhi1cLOSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.countplot(x='Survived',hue='Pclass',data=train,palette='rainbow')"
      ],
      "metadata": {
        "id": "oyoW535nLTpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following code extracts and\n",
        "plots the fraction of passenger count that survived,\n",
        "by each class"
      ],
      "metadata": {
        "id": "lul0PKJmLZKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f_class_survived=train.groupby('Pclass')['Survived'].mean()\n",
        "f_class_survived = pd.DataFrame(f_class_survived)\n",
        "f_class_survived\n",
        "\n",
        "\n",
        "#f_class_survived.plot.bar(y='Survived')\n",
        "#sns.countplot(x='Survived',hue='Pclass',data=f_class_survived,\n",
        "              #palette='rainbow')\n",
        "#plt.title(\"Fraction of passengers survived by class\",\n",
        "          #fontsize=17)"
      ],
      "metadata": {
        "id": "z9hVpmqmLae1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What about any pattern related to having sibling and spouse?\n",
        "\n",
        "It looks like there is a weak trend that chance of survibility increased if there were more number of sibling or spouse"
      ],
      "metadata": {
        "id": "nVRULVJ8Lf_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.countplot(x='Survived',hue='SibSp',data=train,palette='rainbow')"
      ],
      "metadata": {
        "id": "O2doibURLjOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the overall age distribution look like?"
      ],
      "metadata": {
        "id": "3z8svLWXLn_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['Age'].hist()\n",
        "plt.xlabel(\"Age of the passengers\",fontsize=18)\n",
        "plt.ylabel(\"Count\",fontsize=18)\n",
        "plt.title(\"Agewise histogram of the passengers\",fontsize=17)\n",
        "#train['Age'].hist(bins=30,color='darkred',alpha=0.7,figsize=(10,6))\n"
      ],
      "metadata": {
        "id": "tqtHSHIqLpbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does the age distribution look like across passenger class?\n",
        "\n",
        "It looks like that the average age is different for three classes and it generally decreases from 1st class to 3rd class."
      ],
      "metadata": {
        "id": "uN22zpTmLs6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "plt.xlabel(\"Passenger Class\",fontsize=18)\n",
        "plt.ylabel(\"Age\",fontsize=18)\n",
        "sns.boxplot(x='Pclass',y='Age',data=train,palette='winter')"
      ],
      "metadata": {
        "id": "yXMBqrk7Lxjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_class_Age=train.groupby('Pclass')['Age'].mean()\n",
        "f_class_Age = pd.DataFrame(f_class_Age)\n",
        "\n",
        "f_class_Age.plot.bar(y='Age')\n",
        "plt.title(\"Average age of passengers by class\",fontsize=17)\n",
        "plt.ylabel(\"Age (years)\", fontsize=17)\n",
        "plt.xlabel(\"Passenger class\", fontsize=17)"
      ],
      "metadata": {
        "id": "47XohFifL4rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data wrangling (impute and drop)\n",
        "- Impute age (by averaging)\n",
        "- Drop unncessary features\n",
        "- Convert categorical features to dummy variables"
      ],
      "metadata": {
        "id": "I8fUtP2qL8_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=list(f_class_Age['Age'])\n",
        "\n",
        "def impute_age(cols):\n",
        "    Age = cols[0]\n",
        "    Pclass = cols[1]\n",
        "\n",
        "    if pd.isnull(Age):\n",
        "        if Pclass == 1:\n",
        "            return a[0]\n",
        "        elif Pclass == 2:\n",
        "            return a[1]\n",
        "        else:\n",
        "            return a[2]\n",
        "    else:\n",
        "        return Age"
      ],
      "metadata": {
        "id": "QWitg9iqME1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the above-defined function and plot the count of numeric features"
      ],
      "metadata": {
        "id": "PSzOl3daMOdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)\n",
        "d=train.describe()\n",
        "\n",
        "dT=d.T\n",
        "dT.plot.bar(y='count')\n",
        "plt.title(\"Bar plot of numeric features\",fontsize=17)"
      ],
      "metadata": {
        "id": "I_XOsCIPMPfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the 'Cabin' feature and any other null value"
      ],
      "metadata": {
        "id": "KbqVKkDbMTdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop('Cabin',axis=1,inplace=True)\n",
        "train.dropna(inplace=True)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "_mc1Q36dMUeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drop other unnecessary features\n",
        "like 'Cabin','PassengerId', 'Name', 'Ticket'"
      ],
      "metadata": {
        "id": "VyooermyMaZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['PassengerId','Name','Ticket'],axis=1,\n",
        "           inplace=True)\n",
        "train.dropna(inplace=True)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "BRWUb8YmMd8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert categorial feature like 'Sex'\n",
        "and 'Embarked' to dummy variables"
      ],
      "metadata": {
        "id": "n3znlrwQMh0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use pandas 'get_dummies()' function"
      ],
      "metadata": {
        "id": "mdcwP4Z3MmZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sex = pd.get_dummies(train['Sex'],drop_first=True)\n",
        "embark = pd.get_dummies(train['Embarked'],drop_first=True)"
      ],
      "metadata": {
        "id": "q-5C8GbdMo2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now drop the 'Sex' and 'Embarked' columns and concatenate the new dummy variables"
      ],
      "metadata": {
        "id": "SnvIuQ8XMra_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(['Sex','Embarked'],axis=1,inplace=True)\n",
        "train = pd.concat([train,sex,embark],axis=1)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "H7KYpIC3Mux4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\This data set is now ready for logistic regression analysis!"
      ],
      "metadata": {
        "id": "Pj75hNGhMz2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression model fit and prediction\n",
        "Let's start by splitting our data into a training set and test set (there is another test.csv file that you can play around with in case you want to use all this data for training)."
      ],
      "metadata": {
        "id": "jGKGBtHLM4z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train.drop('Survived',axis=1),train['Survived'],\n",
        "    test_size=0.20,random_state=111)"
      ],
      "metadata": {
        "id": "bnuOSunhM70t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1-score as a function of regularization (penalty) parameter"
      ],
      "metadata": {
        "id": "aW-mp9PWM_rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "nsimu=201\n",
        "penalty=[0]*nsimu\n",
        "logmodel=[0]*nsimu\n",
        "predictions =[0]*nsimu\n",
        "class_report = [0]*nsimu\n",
        "f1=[0]*nsimu\n",
        "\n",
        "for i in range(1,nsimu):\n",
        "        logmodel[i] =(LogisticRegression(C=i/1000,tol=1e-4,\n",
        "                                         max_iter=int(1e6),\n",
        "                                         n_jobs=4))\n",
        "        logmodel[i].fit(X_train,y_train)\n",
        "        predictions[i] = logmodel[i].predict(X_test)\n",
        "        class_report[i] = classification_report(y_test,\n",
        "                                                predictions[i])\n",
        "        l=class_report[i].split()\n",
        "        f1[i] = l[len(l)-2]\n",
        "        penalty[i]=1000/i\n",
        "\n",
        "plt.scatter(penalty[1:len(penalty)-2],f1[1:len(f1)-2])\n",
        "plt.title(\"F1-score vs. regularization parameter\",fontsize=20)\n",
        "plt.xlabel(\"Penalty parameter\",fontsize=17)\n",
        "plt.ylabel(\"F1-score on test data\",fontsize=17)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rfsB9Sy-NAhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1-score as a function of test set size (fraction)"
      ],
      "metadata": {
        "id": "oqwY_qGfNFlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nsimu=101\n",
        "class_report = [0]*nsimu\n",
        "f1=[0]*nsimu\n",
        "test_fraction =[0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived',axis=1),\n",
        "                                                    train['Survived'], test_size=0.1+(i-1)*0.007,\n",
        "                                                    random_state=111)\n",
        "        logmodel =(LogisticRegression(C=1,tol=1e-4, max_iter=1000,n_jobs=4))\n",
        "        logmodel.fit(X_train,y_train)\n",
        "        predictions = logmodel.predict(X_test)\n",
        "        class_report[i] = classification_report(y_test,predictions)\n",
        "        l=class_report[i].split()\n",
        "        f1[i] = l[len(l)-2]\n",
        "        test_fraction[i]=0.1+(i-1)*0.007\n",
        "\n",
        "plt.plot(test_fraction[1:len(test_fraction)-2],f1[1:len(f1)-2])\n",
        "plt.title(\"F1-score vs. test set size (fraction)\",fontsize=20)\n",
        "plt.xlabel(\"Test set size (fraction)\",fontsize=17)\n",
        "plt.ylabel(\"F1-score on test data\",fontsize=17)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "43psd6xGNG_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1-score as a function of random seed of test/train split"
      ],
      "metadata": {
        "id": "c-VTqrZnNNdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nsimu=101\n",
        "class_report = [0]*nsimu\n",
        "f1=[0]*nsimu\n",
        "random_init =[0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived',axis=1),\n",
        "                                                    train['Survived'], test_size=0.3,\n",
        "                                                    random_state=i+100)\n",
        "        logmodel =(LogisticRegression(C=1,tol=1e-5, max_iter=1000,n_jobs=4))\n",
        "        logmodel.fit(X_train,y_train)\n",
        "        predictions = logmodel.predict(X_test)\n",
        "        class_report[i] = classification_report(y_test,predictions)\n",
        "        l=class_report[i].split()\n",
        "        f1[i] = l[len(l)-2]\n",
        "        random_init[i]=i+100\n",
        "\n",
        "plt.plot(random_init[1:len(random_init)-2],f1[1:len(f1)-2])\n",
        "plt.title(\"F1-score vs. random initialization seed\",fontsize=20)\n",
        "plt.xlabel(\"Random initialization seed\",fontsize=17)\n",
        "plt.ylabel(\"F1-score on test data\",fontsize=17)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Qan3fOfXNYZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}